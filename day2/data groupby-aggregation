https://www.kaggle.com/unsdsn/world-happiness

The data set is a CSV file called World_Happiness_2015.csv. Below are descriptions for some of the columns we'll be working with:

Country - Name of the country.
Region - Name of the region the country belongs to.
Happiness Rank - The rank of the country, as determined by its happiness score.
Happiness Score - A score assigned to each country based on the answers to a poll question that asks respondents to rate their happiness on a scale of 0-10.
Family - The estimated extent to which family contributes to the happiness score.
Freedom - The estimated extent to which freedom contributes to the happiness score.
Generosity - The estimated extent to which generosity contributes to the happiness score.

1. Use the pd.read_csv() function to read the World_Happiness_2015.csv file into a dataframe called happiness2015.
Store the first five rows of the dataframe in a variable called first_5.
Use the DataFrame.info() method to print information about the dataframe.
After you have run your code, use the variable inspector to look at the variable first_5 and the output to get
familiar with the data.

happiness2015 = pd.read_csv("World_Happiness_2015.csv")
first_5 = happiness2015.head(5)
happiness2015.info()

2. First, let's visualize the happiness score of each country in happiness2015:
happiness2015['Happiness Score'].plot(kind='bar', title='Happiness Scores', ylim=(0,10))
happiness2015['Region'].unique()

"array(['Western Europe', 'North America', 'Australia and New Zealand',
       'Middle East and Northern Africa', 'Latin America and Caribbean',
       'Southeastern Asia', 'Central and Eastern Europe', 'Eastern Asia',
       'Sub-Saharan Africa', 'Southern Asia'], dtype=object)"
       
       
 Let's try plotting just one region next:
 
so_asia = happiness2015[happiness2015['Region'] == 'Southern Asia']
so_asia.plot(x='Country', y='Happiness Score', kind='barh', title='Southern Asia Happiness Scores', xlim=(0,10))
https://s3.amazonaws.com/dq-content/343/asia_happiness.png

It's much easier to read this visualization - we can clearly see the labels and values. However, 
we wouldn't know if the Southern Asia region is representative of the entire world unless we look at the other regions. 
What we really want is to create a visualization that uses one number, a summary statistic like the mean, to summarize
the data for each region.
In this mission, we'll learn how to perform different kinds of aggregations, applying a statistical operation to groups 
of our data, and create visualizations like the one above.

Create an empty dictionary named mean_happiness to store the results of this exercise.
Use the Series.unique() method to create an array of unique values for the Region column.
Use a for loop to iterate over the unique region values from the Region column.
Assign the rows belonging to the current region to a variable named region_group.
Use the Series.mean() method to calculate the mean happiness score for region_group.
Assign the mean value to the mean_happiness dictionary, using the region name as the 
key and the mean happiness score as the value.
mean_happiness = {}
r = happiness2015['Region'].unique()
for i in r:
    region_group = happiness2015[happiness2015['Region'] == i]
    
    region_mean = region_group['Happiness Score'].mean()
    mean_happiness[i] = region_mean
    

3. Let's break down the code we wrote in the previous screen into three steps:

-Split the dataframe into groups.
-Apply a function to each group.
-Combine the results into one data structure.
mean_happiness = {}
regions = happiness2015['Region'].unique()

for r in regions:
    #1. Split the dataframe into groups.
    region_group = happiness2015[happiness2015['Region'] == r]
    #2. Apply a function to each group.
    region_mean = region_group['Happiness Score'].mean()
    #3. Combine the results into one data structure.
    
 The groupby operation performs the "split-apply-combine" process on a dataframe, but condenses it into two steps:
Create a GroupBy object.
Call a function on the GroupBy object.

df.groupby('col')
where col is the column you want to use to group the data set. Note that you can also group the data set on 
multiple columns by passing a list  into the DataFrame.groupby() method.
 
Series.value_counts()
Let's confirm the number of regions and the number of unique values in each region for the entire dataframe
with the Series.value_counts() method next:
happiness2015['Region'].value_counts()

Since there's a small number of groups and each group contains more than one unique value,
we can confirm the Region column is a good candidate to group by.

6. let's create a Groupby object and group the dataframe by the Region column:
happiness2015.groupby('Region')

Before our we start aggregating data, we'll build some intuition around GroupBy objects. 
We'll start by using the GroupBy.get_group() method to select data for a certain group.
As an example, to select the data for just the North America group, we'd pass 'North America' 
into the get_group() method as follows:
grouped = happiness2015.groupby('Region')
grouped.get_group('North America')

Use the df.groupby() method to group happiness2015 by the Region column. Assign the result to grouped.
Use the GroupBy.get_group() method to select the data for the Australia and New Zealand group only.
Assign the result to aus_nz.
grouped = happiness2015.groupby('Region')
aus_nz = grouped.get_group('Australia and New Zealand')

We can also use the GroupBy.groups attribute to get more information about the GroupBy object:
grouped = happiness2015.groupby('Region')
grouped.groups
The result is a dictionary in which each key corresponds to a region name. See below for the first couple of keys:
{'Australia and New Zealand': Int64Index([8, 9], dtype='int64'),
 'Central and Eastern Europe': Int64Index([ 30,  43,  44,  51,  53,  54,  55,  58,  59,  61,  63,  68,  69,
              72,  76,  79,  82,  85,  86,  88,  92,  94,  95, 103, 105, 110, 126, 129, 133], dtype='int64'),
 'Eastern Asia': Int64Index([37, 45, 46, 71, 83, 99],dtype='int64'),
 'Latin America and Caribbean': Int64Index([ 11,  13,  15,  22,  24,  26,  29,  31,  32,  39,  40,  41,  42,
              47,  50,  52,  56,  57,  64,  97, 104, 118], dtype='int64'),
 'Middle East and Northern Africa': Int64Index([ 10,  19,  21,  27,  34,  38,  48,  62,  67,  75,  81,  91, 
              102, 106, 107, 109, 111, 134, 135, 155],dtype='int64'),
 'North America': Int64Index([4, 14], dtype='int64'),
 ...
 }

 Notice that the values include the index for each row in the original happiness2015 dataframe with the corresponding 
 region name. To prove this, let's again look at the data for the Australia and New Zealand group:
 Then, let's filter on indexes 8 and 9 in happiness2015:
 
 happiness2015.iloc[8:10]
 

6. For the following exercise, use the result from the dictionary returned by grouped.groups shown below:
'North America': Int64Index([4, 14], dtype='int64'
Prove that the values for the 'North America' group in the dictionary returned by grouped.groups above correspond to countries in North America in the happiness2015 dataframe.
Use the snippet above to identify the indexes of the countries in happiness2015 that belong to the North America group.
Use the indexes to assign just the countries in North America in happiness2015 to north_america.
Use the GroupBy.get_group() method to select the data for the North America group only. Assign the result to na_group.
Use the following code to compare north_america and na_group: north_america == na_group. Assign the result to equal.

grouped = happiness2015.groupby('Region')
north_america = happiness2015.iloc[[4,14]]
na_group = grouped.get_group('North America')
equal = north_america == na_group

7. In order to aggregate our data, we must call a function on the GroupBy object.
A basic example of aggregation is computing the number of rows for each of the groups. We can use the GroupBy.size() method to 
confirm the size of each region group:
grouped = happiness2015.groupby('Region')
grouped.size()

Region
Australia and New Zealand           2
Central and Eastern Europe         29
Eastern Asia                        6
Latin America and Caribbean        22
Middle East and Northern Africa    20
North America                       2
Southeastern Asia                   9
Southern Asia                       7
Sub-Saharan Africa                 40
Western Europe                     21 
dtype: int64

Notice that the result is a Series and contains just one value for each group. Each value represents the number of 
rows in each group. For example, the 'Australia and New Zealand' group contains two rows.
Pandas has built in a number of other common aggregation methods:
Methods	Description
mean()	Calculates the mean of groups.
sum()	Calculates the sum of group values.
size()	Calculates the size of the groups.
count()	Calculates the count of values in groups.
min()	Calculates the minimum of group values.
max()	Calculates the maximum of group values.

8. In some cases, we may only wish to aggregate one particular column in the original dataframe. 
GroupBy objects actually support column indexing, just like dataframes. 
You can select specific columns for a GroupBy object the same way you would for a dataframe:

Select by Label	Syntax
Single column	GroupBy["col1"]
List of columns	GroupBy[["col1", "col2"]]

grouped = happiness2015.groupby('Region')
happy_grouped = grouped['Happiness Score']
happy_mean = happy_grouped.mean()

9. However, what if we wanted to apply more than one kind of aggregation to a column at a time?

For example, suppose we wanted to calculate both the mean and maximum happiness score for each region

Luckily, however, the GroupBy.agg() method can perform both aggregations at once.
GroupBy.agg([func_name1,func_name2,func_name3])

import numpy as np
grouped = happiness2015.groupby('Region')
happy_grouped = grouped['Happiness Score']
def dif(group):
    return (group.max() - group.mean())
happy_mean_max = happy_grouped.agg([np.mean, np.max])
mean_max_dif = happy_grouped.agg(dif)

11. In the last exercise, we learned we can use the GroupBy.agg() method to:
Perform more than one aggregation at once.
Compute custom aggregations.
However, if you read through other teaching resources, you may see instances in which the statements are combined:

happiness2015.groupby('Region')['Happiness Score'].agg(dif)

When you printed happiness_means, you should've seen that the values in the Region column are the index of the resulting 
dataframe and the Happiness Score column contained the values that would be aggregated:
regin -- index 
happiness score - index 

df.pivot_table(
Index and values are actually arguments used in another method used to aggregate data - the DataFrame.pivot_table() method. 
This df.pivot_table() methodcan perform the same kinds of aggregations as the df.groupby method and make the code for
complex aggregations easier to read.

g=happiness2015.pivot_table(values='Happiness Score',index='Region',aggfunc=np.mean)
Keep in mind that this method returns a dataframe, so normal dataframe filtering and methods can be applied to the result
g.plot()
Note that we exclude aggfunc below because the mean is the default aggregation function of df.pivot_table()
pv_happiness = happiness2015.pivot_table('Happiness Score', 'Region')
pv_happiness.plot(kind='barh', title='Mean Happiness Scores by Region', xlim=(0,10), legend=False)

We've already updated pv_happiness by setting the margins parameter equal to True.
Plot the resulting dataframe, pv_happiness, using the df.plot() method. Set kind to barh, 
xlim to (0,10), title to 'Mean Happiness Scores by Region', and legend to False. What do you notice about this results?
Calculate the mean of the Happiness Score column in the original happiness 2015 data set. Assign the result to 
world_mean_happiness.
Does world_mean_happiness equal the value for the All group? If you can't figure out the answer, 
don't worry! We'll review this question on the next screen.

pv_happiness = happiness2015.pivot_table(values='Happiness Score', index='Region', aggfunc=np.mean, margins=True)
pv_happiness.plot(kind = 'barh',xlim =(0,10),title ='Mean Happiness Scores by Region',legend = False)
world_mean_happiness = happiness2015['Happiness Score'].mean()

