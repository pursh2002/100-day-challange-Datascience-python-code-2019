- https://towardsdatascience.com/let-us-understand-the-correlation-matrix-and-covariance-matrix-d42e6b643c22
- https://www.listendata.com/2014/08/learn-area-under-
curve-auc.html?fbclid=IwAR2NmguvPWQp0CWoA-cA6jJxHedgkZWp_O4Uxav4UF34HmoTCl5zVKemV8w
- https://www.khanacademy.org/math/statistics-probability/
- random-variables-stats-library/random-variables-discrete/v/discrete-and-continuous-random-variables

- https://www.khanacademy.org/math/statistics-probability

- https://www.khanacademy.org/math/probability
https://revisionmaths.com/advanced-level-maths-revision/statistics/continuous-random-variables


#49: Probability Mass Function(PMF) & Probability Density Function (PDF)
-----------------------------------------------------------------
The probability that a discrete random variable X takes on a particular value x, i.e., P(X = x), 
denoted as f(x), is called the probability mass function. This function gives the probability that a 
discrete random variable is exactly equal to some value. It is often the primary means of defining a 
discrete probability distribution, and such functions exist for either scalar or multivariate random 
variables whose domain is discrete.

The probability that a continuous random variable X takes on a range (a,b), i.e., f(a,b)=P(a<X<b) is 
called the probability density function. It is a statistical expression that defines a probability 
distribution for a continuous random variable. When the PDF is graphically portrayed, the area under 
the curve will indicate the interval in which the variable will fall. The total area in this interval 
of the graph equals the probability of a continuous random variable occurring. 

E.g. the probability that today's temperature will be 80 degrees (80 degrees exactly) is measured by 
PMF and the probability that the temperature will be between 80 and 85 degrees is measured by PDF.

https://machinelearningmastery.com/probability-resources-for-machine-learning/


#50: Sampling with replacement and without replacement
-----------------------
Sampling 'with replacement' means that when a unit selected at random from the population, it is returned to the 
population (replaced), and then a second element is selected at random. Here, the two sample values are independent 
i.e. what we get on the first one doesn't affect what we get on the second. The covariance between the two is zero.
Sampling 'without replacement' means when a unit selected at random from the population, it is not returned to the 
population (replaced), and then a second element is selected at random. Each sample unit of the population has only 
one chance to be selected in the sample. Here, the two sample values aren't independent i.e. what we got on the for 
the first one affects what we can get for the second one. The covariance between the two isn't zero. Here, the covariance 
depends on the population size. If the population is very large, this covariance is very close to zero. In that case, 
sampling with replacement isn't much different from sampling without replacement. sometimes, this difference is described 
as 
sampling from an infinite population (sampling with replacement) vs sampling from a finite population (without replacement).

#53:Z-score
-----------
A Z-score is a numerical measurement used in statistics of a value's relationship to the mean 
(average) of a group of values, measured in terms of standard deviations from the mean. 
Simply put, a z-score is the number of standard deviations from the mean a data point is.
If a Z-score is 0, it indicates that the data point's score is identical to the mean score. 
A Z-score of 1.0 would indicate a value that is one standard deviation from the mean. 
Z-scores may be positive or negative, with a positive value indicating the score is above 
the mean and a negative score indicating it is below the mean.
The basic z score formula for a sample is:
z = (x – μ) / σ
For example, let’s say you have a IIT entrance test score of 210. The test has a mean (μ) of
170 and a standard deviation (σ) of 15. Assuming a normal distribution, your z score would be:
z = (x – μ) / σ
= (210 – 170) / 15 = 2.67

This means that your score is 2.67 away from mean. This illustrates that you have very high score 
and you are one of the toppers in the test. This again depends on the population size. This also has to be kept in mind.


#59: Principle of Least Square 
-------------------------------
The least squares principle states that the Sample Regression Function (SRF) should be constructed (with the constant and slope values such as Y=aX+b ) so that the sum of the squared distance between the observed values of the dependent variable and the values estimated from SRF is minimized (the smallest possible value).

Let (xi,yi) be the observed data points and (x'i,y'i) is estimated data point(data point on regression line corresponding to xi,yi i.e. vertical deviation from data point to the regression line), then least square principal says that  ∑ (xi-x'i)^2+(yi-y'i)^2 has to be minimized to get best fit regression line. 

Least squares principle is a widely used method for obtaining the estimates of the parameters in a statistical model based on observed data.
 
Other techniques, including generalized method of moments (GMM) and maximum likelihood (ML) estimation, can be used to estimate regression functions, but they require more mathematical sophistication and more computing power.

Least squares is sensitive to outliers. A strange value will pull the line towards i


Dear Aspiring Data Scientists and (Bio)statisticians. I am often asked, whether it's allowed to analyse ordinal data with parametric methods, e.g. by assigning to it numbers (1,2,3, etc.). My answer is: *technically* you can do everything. But does it REALLY make any sense? Think about it.

Do you understand, what "ordinal" means? Only the order between the levels is defined. A>B>C>D. There's no numerical distance between the levels, no subtraction, no division. You cannot say: Good-Average=Bad, or Good-Average=Average-Bad. Sure, you can assign {1,2,3,4} to your items and treat as numbers (pretending it's even continuous, normal), calculate your regression or t-test. Now try to interpret it. What does 1.43 maps to? "Good"? "0.43*Bad"? What is "the mean of {bad=1,good=4}? 2.?

You assigned numerical values to levels (subjectively) and made a STRONG assumption about the equality of distances. Can you do that? If so (e.g. Likert scale with many levels, combined into the final score) - maybe(!) it's OK (people vary in opinions)

In R, you have plenty of options to handle it properly. The best way is the ordinal logit/probit (proportional odds) model (ordinal logistic regression). Then you have, ATS/WTS, ART, GEE.
