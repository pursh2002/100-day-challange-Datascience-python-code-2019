Missing or duplicate data may exist in a data set for a number of different reasons. Sometimes, missing or duplicate data is introduced as we perform cleaning and transformation tasks such as:

Combining data
Reindexing data
Reshaping data

In the Pandas Fundamentals course, we learned that there are various ways to handle missing data:

Remove any rows that have missing values.
Remove any columns that have missing values.
Fill the missing values with some other value.
Leave the missing values as is.
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.shape.html

1. 
We've already read in the modified 2015, 2016, and 2017 World Happiness Reports to the variables happiness2015, happiness2016, and happiness2017, respectively. We also updated each dataframe so that each contain the same countries, as described above.
Use the DataFrame.shape attribute to confirm the number of rows and columns for happiness2015, happiness2016, and happiness2017.
Assign the result for happiness2015 to shape_2015.
Assign the result for happiness2016 to shape_2016.
Assign the result for happiness2017 to shape_2017.

shape_2015 = happiness2015.shape 
shape_2016 = happiness2016.shape
shape_2017 = happiness2017.shape 

2. 
In pandas, missing values are generally represented by the NaN value, as seen in the dataframe above, or the None value.
https://stackoverflow.com/questions/40011531/in-pandas-when-using-read-csv-how-to-assign-a-nan-to-a-value-thats-not-the#answer-40011736
However, it's good to note that pandas will not automatically identify values such as n/a, -, or -- as NaN or None, 
but they may also indicate data is missing. 
See here for more information on how to use the pd.read_csv() function to read those values in as NaN.

Once we ensure that all missing values were read in correctly, 
we can use the Series.isnull() method to identify rows with missing values:

missing = happiness2015['Happiness Score'].isnull()
happiness2015[missing]
happiness2015[missing].isnull()

happiness2015.isnull().sum() 

missing_2016 = happiness2016.isnull().sum()
missing_2017 = happiness2017.isnull().sum()

If we do introduce missing values after transforming data, we'll have to determine if the data is really missing or if it's the result of some kind of error. As we progress through this mission, we'll use the following workflow to clean our missing values, starting with checking for errors:

Check for errors in data cleaning/transformation.
Use data from additional sources to fill missing values.
Drop row/column.
Fill missing values with reasonable estimates computed from the available data.
combined = pd.concat([happiness2015, happiness2016, happiness2017], ignore_index=True)
combined.isnull().sum()
Country                            0
Dystopia Residual                177
Dystopia.Residual                337
Economy (GDP per Capita)         177
Economy..GDP.per.Capita.         337
Family                            22
Freedom                           22
Generosity                        22
Happiness Rank                   177
Happiness Score                  177
Happiness.Rank                   337
Happiness.Score                  337
Health (Life Expectancy)         177
Health..Life.Expectancy.         337
Lower Confidence Interval        335
Region                           177
Standard Error                   334
Trust (Government Corruption)    177
Trust..Government.Corruption.    337
Upper Confidence Interval        335
Whisker.high                     337
Whisker.low                      337
Year                               0
dtype: int64

We can see above that our dataframe has many missing values and 
these missing values follow a pattern. Most columns fall into one of the following categories:

177 missing values (about 1/3 of the total values)
337 missing values (about 2/3 of the total values)
You may have also noticed that some of the column names differ only by punctuation, 
which caused the dataframes to be combined incorrectly:

You may have also noticed that some of the column names differ only by punctuation, which caused the dataframes to be combined incorrectly:

Trust (Government Corruption)
Trust..Government.Corruption.

https://stackoverflow.com/questions/39741429/pandas-replace-a-character-in-all-column-names
As a reminder, below is a list of common string methods you can use to clean the columns:

Method	Description
Series.str.split()	Splits each element in the Series.
Series.str.strip()	Strips whitespace from each string in the Series.
Series.str.lower()	Converts strings in the Series to lowercase.
Series.str.upper()	Converts strings in the Series to uppercase.
Series.str.get()	Retrieves the ith element of each element in the Series.
Series.str.replace()	Replaces a regex or string in the Series with another string.
Series.str.cat()	Concatenates strings in a Series.
Series.str.extract()	Extracts substrings from the Series matching a regex pattern.

3. 
We've already updated the column names for happiness2017.
Update the columns names forhappiness2015 and happiness2016 to match the formatting of the column names in happiness2017. Use the following criteria to rename the columns:
All letters should be uppercase.
There should be only one space between words.
There should be no parentheses in column names
For example, the Health (Life Expectancy) columns should both be renamed to HEALTH LIFE EXPECTANCY.
Use the pd.concat() function to combine happiness2015, happpiness2016, and happiness2017. 
Set the ignore_index argument equal to True to reset the index in the resulting dataframe. 
Assign the result to combined.
Use the DataFrame.isnull() and DataFrame.sum() methods to check for missing values. 
Assign the result to a variable named missing.

happiness2017.columns = happiness2017.columns.str.replace('.', ' ').str.replace('\s+', ' ').str.strip().str.upper()

happiness2015.columns = happiness2015.columns.str.replace(r'[\(\)]', '').str.strip().str.upper()
happiness2016.columns = happiness2016.columns.str.replace(r'[\(\)]', '').str.strip().str.upper()
combined = pd.concat([happiness2015,happiness2016,happiness2017], ignore_index =True)

missing = combined.isnull().sum()





